{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ca1cc3d",
   "metadata": {},
   "source": [
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fcf810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    classification_report,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35997bc9",
   "metadata": {},
   "source": [
    "#### Load dataset and name columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f5a0c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"dataset/SMSSpamCollection\", sep=\"\\t\", header=None, names=[\"target\", \"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab403e9f",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a321ca7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ã¼ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                               text\n",
       "0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       ham  U dun say so early hor... U c already then say...\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "5567   spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568    ham               Will Ã¼ b going to esplanade fr home?\n",
       "5569    ham  Pity, * was in mood for that. So...any other s...\n",
       "5570    ham  The guy did some bitching but I acted like i'd...\n",
       "5571    ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a8164189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   target  5572 non-null   str  \n",
      " 1   text    5572 non-null   str  \n",
      "dtypes: str(2)\n",
      "memory usage: 87.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "863db462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96717df1",
   "metadata": {},
   "source": [
    "#### Convert string targets to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cf5279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target = df.target.map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed09acae",
   "metadata": {},
   "source": [
    "#### Separate text and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f711bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"text\"]  # SMS\n",
    "y = df[\"target\"]  # Labels: 1 = Spam, 0 = No Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0a5c66",
   "metadata": {},
   "source": [
    "#### split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1440c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9254cbc7",
   "metadata": {},
   "source": [
    "#### Method to perform manual cross-validation with optional calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6fae376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_CV(model, X_train, y_train, calibrate):\n",
    "    # Initialize StratifiedKFold for cross-validation with 5 splits\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Lists to store F1 scores and best thresholds for each fold\n",
    "    f1_scores = []\n",
    "    best_thresholds = []\n",
    "\n",
    "    # Iterate over each train-validation split\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        # Split the data into training and validation sets\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # Check if calibration is required\n",
    "        if calibrate:\n",
    "            # Create a calibrated classifier using sigmoid method\n",
    "            model_fold = CalibratedClassifierCV(\n",
    "                model,\n",
    "                method=\"sigmoid\",\n",
    "                cv=5\n",
    "            )\n",
    "        else:\n",
    "            # Use the original model if no calibration is needed\n",
    "            model_fold = model\n",
    "\n",
    "        # Fit the model on the training data\n",
    "        model_fold.fit(X_tr, y_tr)\n",
    "\n",
    "        # Check if the model has a predict_proba method\n",
    "        if hasattr(model_fold, \"predict_proba\"):\n",
    "            # Get predicted probabilities for the positive class\n",
    "            probs = model_fold.predict_proba(X_val)[:, 1]\n",
    "        else:\n",
    "            # Use decision function if predict_proba is not available\n",
    "            probs = model_fold.decision_function(X_val)\n",
    "\n",
    "        # Calculate precision, recall, and thresholds for the validation set\n",
    "        precision, recall, thresholds = precision_recall_curve(y_val, probs)\n",
    "\n",
    "        # Exclude the last precision and recall values for threshold alignment\n",
    "        precision = precision[:-1]\n",
    "        recall = recall[:-1]\n",
    "\n",
    "        # Calculate the F1 score for the precision-recall curve\n",
    "        f1_curve = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "\n",
    "        # Find the index of the best F1 score\n",
    "        best_idx = np.argmax(f1_curve)\n",
    "\n",
    "        # Append the best F1 score and corresponding threshold to the lists\n",
    "        f1_scores.append(f1_curve[best_idx])\n",
    "        best_thresholds.append(thresholds[best_idx])\n",
    "\n",
    "    # Return the mean F1 score and mean of the best thresholds across all folds\n",
    "    return np.mean(f1_scores), np.mean(best_thresholds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8b19d2",
   "metadata": {},
   "source": [
    "#### Method to optimize LogisticRegression classifier using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "616897aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.948606: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:25<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LogisticRegression F1: 0.9486\n",
      "Best threshold : 0.6520\n",
      "Best LogisticRegression Params:\n",
      "   ngram_range: 1_1\n",
      "   max_features: 12612\n",
      "   min_df: 5\n",
      "   C: 7.333758903560418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def objective_logreg(trial):\n",
    "    # Suggest a categorical value for n-gram range from predefined options\n",
    "    ngram_range_str = trial.suggest_categorical(\"ngram_range\", [\"1_1\", \"1_2\"])\n",
    "    # Convert the string representation of n-gram range to a tuple of integers\n",
    "    ngram_range = tuple(map(int, ngram_range_str.split(\"_\")))\n",
    "\n",
    "    # Create a pipeline consisting of TF-IDF vectorization and logistic regression\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\n",
    "                \"tfidf\",  # Name of the first step in the pipeline\n",
    "                TfidfVectorizer(\n",
    "                    ngram_range=ngram_range,  # Set the n-gram range for vectorization\n",
    "                    max_features=trial.suggest_int(\"max_features\", 5000, 30000),  # Suggest max features\n",
    "                    min_df=trial.suggest_int(\"min_df\", 1, 5),  # Suggest minimum document frequency\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"clf\",  # Name of the second step in the pipeline\n",
    "                LogisticRegression(\n",
    "                    C=trial.suggest_float(\"C\", 0.01, 10.0, log=True),  # Suggest regularization strength\n",
    "                    class_weight=\"balanced\",  # Use balanced class weights\n",
    "                    max_iter=300,  # Set maximum iterations for convergence\n",
    "                    solver=\"liblinear\",  # Specify the solver for optimization\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    # Perform manual cross-validation and retrieve mean F1 score and threshold\n",
    "    mean_f1, mean_threshold = manual_CV(pipeline, X_train, y_train, calibrate=False)\n",
    "    # Store the best threshold found during cross-validation in trial attributes\n",
    "    trial.set_user_attr(\"best_threshold\", mean_threshold)\n",
    "\n",
    "    # Return the mean F1 score for the current trial\n",
    "    return mean_f1\n",
    "\n",
    "\n",
    "# Create an Optuna study to optimize the logistic regression model\n",
    "study_logreg = optuna.create_study(\n",
    "    direction=\"maximize\",  # Aim to maximize the objective function\n",
    "    study_name=\"study logreg\",  # Name of the study for identification\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),  # Use TPE sampler with a fixed seed for reproducibility\n",
    ")\n",
    "# Optimize the objective function over a specified number of trials\n",
    "study_logreg.optimize(objective_logreg, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "# Print the best F1 score achieved during the optimization\n",
    "print(f\"Best LogisticRegression F1: {study_logreg.best_value:.4f}\")\n",
    "best_trial = study_logreg.best_trial  # Retrieve the best trial from the study\n",
    "best_threshold_logreg = best_trial.user_attrs[\"best_threshold\"]  # Get the best threshold from trial attributes\n",
    "# Print the best threshold found\n",
    "print(f\"Best threshold : {best_threshold_logreg:.4f}\")\n",
    "print(\"Best LogisticRegression Params:\")\n",
    "# Iterate through the best parameters and print them\n",
    "for k, v in study_logreg.best_params.items():\n",
    "    print(f\"   {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528664f",
   "metadata": {},
   "source": [
    "#### Method to optimize LinearSVC classifier using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8b278ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.954241: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [03:08<00:00,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM F1:  0.9542\n",
      "Best threshold : 0.4113\n",
      "Best SVM Params:\n",
      "   ngram_range: 1_2\n",
      "   max_features: 12281\n",
      "   min_df: 2\n",
      "   C: 1.5106535540253345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def objective_svm(trial):\n",
    "\n",
    "    ngram_range_str = trial.suggest_categorical(\"ngram_range\", [\"1_1\", \"1_2\"])\n",
    "    \n",
    "    ngram_range = tuple(map(int, ngram_range_str.split(\"_\")))\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\n",
    "                \"tfidf\",\n",
    "                TfidfVectorizer(\n",
    "                    ngram_range=ngram_range,\n",
    "                    max_features=trial.suggest_int(\"max_features\", 5000, 30000),\n",
    "                    min_df=trial.suggest_int(\"min_df\", 1, 5),\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"clf\",\n",
    "                LinearSVC(\n",
    "                    C=trial.suggest_float(\"C\", 0.01, 10.0, log=True),\n",
    "                    class_weight=\"balanced\",\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    mean_f1, mean_threshold = manual_CV(pipeline, X_train, y_train, calibrate=True)\n",
    "    trial.set_user_attr(\"best_threshold\", mean_threshold)\n",
    "\n",
    "    return mean_f1\n",
    "\n",
    "\n",
    "study_svm = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"study svm\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    ")\n",
    "study_svm.optimize(objective_svm, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "print(f\"Best SVM F1:  {study_svm.best_value:.4f}\")\n",
    "best_trial = study_svm.best_trial\n",
    "best_threshold_svm = best_trial.user_attrs[\"best_threshold\"]\n",
    "print(f\"Best threshold : {best_threshold_svm:.4f}\")\n",
    "print(\"Best SVM Params:\")\n",
    "for k, v in study_svm.best_params.items():\n",
    "    print(f\"   {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6873f0ae",
   "metadata": {},
   "source": [
    "#### Method to optimize LightGBM classifier using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "251c2880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.918805: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [06:30<00:00,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LGB F1: 0.9188\n",
      "Best threshold : 0.2492\n",
      "Best LGB Params:\n",
      "   n_estimators: 178\n",
      "   num_leaves: 28\n",
      "   learning_rate: 0.08822192250884218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def objective_lgb(trial):\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"tfidf\", TfidfVectorizer(ngram_range=(1, 2), max_features=20000)),\n",
    "            (\n",
    "                \"clf\",\n",
    "                lgb.LGBMClassifier(\n",
    "                    n_estimators=trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "                    num_leaves=trial.suggest_int(\"num_leaves\", 20, 150),\n",
    "                    learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "                    class_weight=\"balanced\",\n",
    "                    verbose=-1,\n",
    "                    n_jobs=-1,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    mean_f1, mean_threshold = manual_CV(pipeline, X_train, y_train, calibrate=False)\n",
    "    trial.set_user_attr(\"best_threshold\", mean_threshold)\n",
    "\n",
    "    return mean_f1\n",
    "\n",
    "\n",
    "study_lgb = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"study lgb\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    ")\n",
    "study_lgb.optimize(objective_lgb, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "print(f\"Best LGB F1: {study_lgb.best_value:.4f}\")\n",
    "best_trial = study_lgb.best_trial\n",
    "best_threshold_lgb = best_trial.user_attrs[\"best_threshold\"]\n",
    "print(f\"Best threshold : {best_threshold_lgb:.4f}\")\n",
    "print(\"Best LGB Params:\")\n",
    "for k, v in study_lgb.best_params.items():\n",
    "    print(f\"   {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40de4a3",
   "metadata": {},
   "source": [
    "#### Show threshold of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b6d2383d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold LogisticRegression: 0.6520\n",
      "Best threshold LinearSVC:          0.4113\n",
      "Best threshold LGBMClassifier:     0.2492\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best threshold LogisticRegression: {best_threshold_logreg:.4f}\")\n",
    "print(f\"Best threshold LinearSVC:          {best_threshold_svm:.4f}\")\n",
    "print(f\"Best threshold LGBMClassifier:     {best_threshold_lgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e97c2c",
   "metadata": {},
   "source": [
    "#### Show F1 of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c66170ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LogisticRegression F1: 0.9486\n",
      "Best LinearSVC F1:          0.9542\n",
      "Best LGBMClassifier F1:     0.9188\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best LogisticRegression F1: {study_logreg.best_value:.4f}\")\n",
    "print(f\"Best LinearSVC F1:          {study_svm.best_value:.4f}\")\n",
    "print(f\"Best LGBMClassifier F1:     {study_lgb.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a11b4b",
   "metadata": {},
   "source": [
    "#### ðŸ“Š Comparison\n",
    "\n",
    "| Aspect                   | LogReg    | SVM       | LightGBM  |\n",
    "| ------------------------ | --------- | --------- | --------- |\n",
    "| F1                       | ðŸ¥ˆ 0.9486 | ðŸ¥‡ 0.9542 | ðŸ¥‰ 0.9188 |\n",
    "| Optimal Threshold        | 0.6520    | 0.4113    | 0.2492    |\n",
    "| Interpretability         | High      | Medium    | Low       |\n",
    "| Calibrated probabilities | Yes       | Yes       | Yes       |\n",
    "| Hardiness                | High      | High      | Medium    |\n",
    "| Risk of overfitting      | Low       | Low       | Medium    |\n",
    "| Speed                    | Very high | High      | Medium    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683dcf1d",
   "metadata": {},
   "source": [
    "#### ðŸ¥ˆ Logistic Regression\n",
    "\n",
    "- F1: **0.9486**, very strong and close to the best.\n",
    "- High optimal threshold (0.6520) â†’ more conservative, favors precision.\n",
    "- Naturally calibrated probabilities and high interpretability.\n",
    "- Stable, simple, and production-friendly.\n",
    "\n",
    "#### ðŸ¥‡ LinearSVC \n",
    "\n",
    "- F1: **0.9542**, best overall performance.\n",
    "- Moderate threshold (0.4113) â†’ more balanced recall/precision trade-off.\n",
    "- Margin-based optimization slightly improves classification boundary.\n",
    "- Slightly more complex than LogReg but still robust.\n",
    "\n",
    "#### ðŸ¥‰ LGBMClassifier\n",
    "\n",
    "- F1: **0.9188**, clearly below linear models.\n",
    "- Very low threshold (0.2492) â†’ needs aggressive recall to compensate.\n",
    "- Higher model complexity without performance gain.\n",
    "- Likely unnecessary capacity for this problem.\n",
    "\n",
    "#### ðŸŽ¯ Conclusion\n",
    "\n",
    "- The problem appears largely linearly separable.<br>\n",
    "- **LinearSVC is the winner** in pure performance (highest F1).<br>\n",
    "- However, Logistic Regression remains a strong alternative if interpretability and simplicity are priorities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0f252",
   "metadata": {},
   "source": [
    "#### LinearSVC optimization history\n",
    "![study_xgb](dataset/svm.png \"LinearSVC Optimization History \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11958afb",
   "metadata": {},
   "source": [
    "#### Instantiate the LinearSVC Pipeline and obtain predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6296e7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       966\n",
      "           1       1.00      0.91      0.95       149\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.99      0.96      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n",
      "[[966   0]\n",
      " [ 13 136]]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best parameters from the SVM study results\n",
    "best_svm = study_svm.best_params\n",
    "\n",
    "# Convert the ngram_range string into a tuple of integers\n",
    "ngram_range = tuple(map(int, best_svm[\"ngram_range\"].split(\"_\")))\n",
    "\n",
    "# Create a pipeline for the SVM model with TF-IDF vectorization and a linear SVC classifier\n",
    "pipeline_svm = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"tfidf\",  # Name of the step in the pipeline\n",
    "            TfidfVectorizer(\n",
    "                ngram_range=ngram_range,  # Set the n-gram range for the vectorizer\n",
    "                max_features=best_svm[\"max_features\"],  # Limit the number of features\n",
    "                min_df=best_svm[\"min_df\"],  # Set the minimum document frequency\n",
    "            ),\n",
    "        ),\n",
    "        (\"clf\", LinearSVC(C=best_svm[\"C\"], class_weight=\"balanced\")),  # Classifier step with balanced class weights\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline_svm.fit(X_train, y_train)\n",
    "\n",
    "# Obtain the decision function scores for the test data\n",
    "scores = pipeline_svm.decision_function(X_test)\n",
    "\n",
    "# Generate predictions based on the decision function scores and the best threshold\n",
    "y_pred_svm = (scores >= best_threshold_svm).astype(int)\n",
    "\n",
    "# Print the classification report for the Linear SVM model\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399345ae",
   "metadata": {},
   "source": [
    "#### Show predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "860229e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Target</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>Squeeeeeze!! This is christmas hug.. If u lik ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>And also I've sorta blown him off a couple tim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>Mmm thats better now i got a roast down me! iÂ’...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>Mm have some kanji dont eat anything heavy ok</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>So there's a ring that comes with the guys cos...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>Den only weekdays got special price... Haiz......</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>I not busy juz dun wan 2 go so early.. Hee..</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>Yes i have. So that's why u texted. Pshew...mi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>How are you enjoying this semester? Take care ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td>G.W.R</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Target  Predicted\n",
       "3245  Squeeeeeze!! This is christmas hug.. If u lik ...       0          0\n",
       "944   And also I've sorta blown him off a couple tim...       0          0\n",
       "1044  Mmm thats better now i got a roast down me! iÂ’...       0          0\n",
       "2484      Mm have some kanji dont eat anything heavy ok       0          0\n",
       "812   So there's a ring that comes with the guys cos...       0          0\n",
       "...                                                 ...     ...        ...\n",
       "4264  Den only weekdays got special price... Haiz......       0          0\n",
       "2439      I not busy juz dun wan 2 go so early.. Hee..        0          0\n",
       "5556  Yes i have. So that's why u texted. Pshew...mi...       0          0\n",
       "4205  How are you enjoying this semester? Take care ...       0          0\n",
       "4293                                              G.W.R       0          0\n",
       "\n",
       "[1115 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame()\n",
    "predictions_df['Text'] = X_test\n",
    "predictions_df['Target'] = y_test\n",
    "predictions_df['Predicted'] = y_pred_svm\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13c697b",
   "metadata": {},
   "source": [
    "0 = Non-spam<br>\n",
    "1 = spam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
